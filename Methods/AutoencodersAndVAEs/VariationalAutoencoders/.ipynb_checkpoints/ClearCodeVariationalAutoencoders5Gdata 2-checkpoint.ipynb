{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ef42a0-cd39-416c-bc0c-16e72fbfefb8",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (Encoding/Decoding) using Auto Encoders\n",
    "\n",
    "Author: Gabriel Rodrigues Palma\n",
    "Purpose: Encode and decode 5G data. Also, generate new dasets based on the autoencoders methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754cecc3-85e6-4d1b-aa70-83ae2906c7a6",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf2b002c-d298-4d69-bb36-bfc71a91ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tf_slim as slim\n",
    "%matplotlib inline\n",
    "Bernoulli = tf.compat.v1.distributions.Bernoulli\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c5e29f-1156-48b3-841f-e421eaa8989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5d985-67e1-464c-9361-c01cc3bfdba4",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b27daa-3bcc-4b53-a036-4a07b21fda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "  U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "  return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "  \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "  y = logits + sample_gumbel(tf.shape(logits))\n",
    "  return tf.nn.softmax( y / temperature)\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "  \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "  Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "  Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "  \"\"\"\n",
    "  y = gumbel_softmax_sample(logits, temperature)\n",
    "  if hard:\n",
    "    k = tf.shape(logits)[-1]\n",
    "    #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "    y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "    y = tf.stop_gradient(y_hard - y) + y\n",
    "  return y\n",
    "\n",
    "def save_anim(data,figsize,filename):\n",
    "  fig=plt.figure(figsize=(figsize[1]/10.0,figsize[0]/10.0))\n",
    "  im = plt.imshow(data[0].reshape(figsize),cmap=plt.cm.gray,interpolation='none')\n",
    "  plt.gca().set_axis_off()\n",
    "  #fig.tight_layout()\n",
    "  fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "  def updatefig(t):\n",
    "    im.set_array(data[t].reshape(figsize))\n",
    "    return im,\n",
    "  anim=animation.FuncAnimation(fig, updatefig, frames=100, interval=50, blit=True, repeat=True)\n",
    "  Writer = animation.writers['imagemagick']\n",
    "  writer = Writer(fps=1, metadata=dict(artist='Me'), bitrate=1800)\n",
    "  anim.save(filename, writer=writer)\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92198531-ca7b-420c-a4f0-5632f613e925",
   "metadata": {},
   "source": [
    "# Categorical Varietional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddeaed0-4ecb-493a-926d-29d33bddf071",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ecf2cd9-b166-407e-ac2a-e4be108f92bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m \u001b[38;5;66;03m# number of categorical distributions\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# input image x (shape=(batch_size,784))\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# variational posterior q(y|x), i.e. the encoder (shape=(batch_size,200))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m net \u001b[38;5;241m=\u001b[39m slim\u001b[38;5;241m.\u001b[39mstack(x,slim\u001b[38;5;241m.\u001b[39mfully_connected,[\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m256\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/ericsson/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:3343\u001b[0m, in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m\"\"\"Inserts a placeholder for a tensor that will be always fed.\u001b[39;00m\n\u001b[1;32m   3297\u001b[0m \n\u001b[1;32m   3298\u001b[0m \u001b[38;5;124;03m**Important**: This tensor will produce an error if evaluated. Its value must\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m-> 3343\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.placeholder() is not compatible with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3344\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mplaceholder(dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "K=10 # number of classes\n",
    "N=30 # number of categorical distributions\n",
    "\n",
    "# input image x (shape=(batch_size,784))\n",
    "x = tf.compat.v1.placeholder(dtype = tf.float32,shape = (None,784))\n",
    "# variational posterior q(y|x), i.e. the encoder (shape=(batch_size,200))\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "# unnormalized logits for N separate K-categorical distributions (shape=(batch_size*N,K))\n",
    "logits_y = tf.reshape(slim.fully_connected(net,K*N,activation_fn=None),[-1,K])\n",
    "q_y = tf.nn.softmax(logits_y)\n",
    "log_q_y = tf.log(q_y+1e-20)\n",
    "# temperature\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    "# sample and reshape back (shape=(batch_size,N,K))\n",
    "# set hard=True for ST Gumbel-Softmax\n",
    "y = tf.reshape(gumbel_softmax(logits_y,tau,hard=False),[-1,N,K])\n",
    "# generative model p(x|y), i.e. the decoder (shape=(batch_size,200))\n",
    "net = slim.stack(slim.flatten(y),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "# (shape=(batch_size,784))\n",
    "p_x = Bernoulli(logits=logits_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "839d0cf2-32c0-45d3-ac3b-d39e5cb7c386",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# loss and train ops\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kl_tmp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mq_y\u001b[49m\u001b[38;5;241m*\u001b[39m(log_q_y\u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mK)),[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,N,K])\n\u001b[1;32m      3\u001b[0m KL \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(kl_tmp,[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      4\u001b[0m elbo\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_sum(p_x\u001b[38;5;241m.\u001b[39mlog_prob(x),\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m KL\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_y' is not defined"
     ]
    }
   ],
   "source": [
    "# loss and train ops\n",
    "kl_tmp = tf.reshape(q_y*(log_q_y-tf.log(1.0/K)),[-1,N,K])\n",
    "KL = tf.reduce_sum(kl_tmp,[1,2])\n",
    "elbo=tf.reduce_sum(p_x.log_prob(x),1) - KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa685112-da73-42d7-82b2-3dbf7d90482b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elbo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;241m-\u001b[39m\u001b[43melbo\u001b[49m)\n\u001b[1;32m      2\u001b[0m lr\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_op\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate\u001b[38;5;241m=\u001b[39mlr)\u001b[38;5;241m.\u001b[39mminimize(loss,var_list\u001b[38;5;241m=\u001b[39mslim\u001b[38;5;241m.\u001b[39mget_model_variables())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'elbo' is not defined"
     ]
    }
   ],
   "source": [
    "loss=tf.reduce_mean(-elbo)\n",
    "lr=tf.constant(0.001)\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,var_list=slim.get_model_variables())\n",
    "init_op=tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b43e28-79e5-48d2-bcb4-5c5e4cd21b34",
   "metadata": {},
   "source": [
    "# Trainning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5419bf79-b3f2-437f-a195-270baf7346af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=100\n",
    "NUM_ITERS=50000\n",
    "tau0=1.0 # initial temperature\n",
    "np_temp=tau0\n",
    "np_lr=0.001\n",
    "ANNEAL_RATE=0.00003\n",
    "MIN_TEMP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e509e3-f19b-42d2-8297-95736a4e30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=[]\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "for i in range(1,NUM_ITERS):\n",
    "  np_x,np_y=data.next_batch(BATCH_SIZE)\n",
    "  _,np_loss=sess.run([train_op,loss],{\n",
    "      x:np_x,\n",
    "      tau:np_temp,\n",
    "      lr:np_lr\n",
    "    })\n",
    "  if i % 100 == 1:\n",
    "    dat.append([i,np_temp,np_loss])\n",
    "  if i % 1000 == 1:\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    np_lr*=0.9\n",
    "  if i % 5000 == 1:\n",
    "    print('Step %d, ELBO: %0.3f' % (i,-np_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031ba8c-c6d8-4d69-964a-00194c732f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x1,_=data.next_batch(100)\n",
    "np_x2,np_y1 = sess.run([p_x.mean(),y],{x:np_x1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad87f9-abdb-46f5-9f27-f40490180ae6",
   "metadata": {},
   "source": [
    "# Performance visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d86949-3858-4e9e-9b12-b4aa8a34daa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dat\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mdat\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "dat=np.array(dat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c11d82-1da1-40f3-b9fe-88659c79e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2)\n",
    "axarr[0].plot(dat[0],dat[1])\n",
    "axarr[0].set_ylabel('Temperature')\n",
    "axarr[1].plot(dat[0],dat[2])\n",
    "axarr[1].set_ylabel('-ELBO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d62e1-492b-4aa9-aafc-ba81eeac4c71",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db39e7e6-31ce-48a2-bbaf-6b419daedde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=100*N\n",
    "np_y = np.zeros((M,K))\n",
    "np_y[range(M),np.random.choice(K,M)] = 1\n",
    "np_y = np.reshape(np_y,[100,N,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac87b3ac-a331-4a21-88a8-3cd73fc88c03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_p\u001b[38;5;241m=\u001b[39m\u001b[43mp_x\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      2\u001b[0m np_x\u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(x_p,{y:np_y})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_x' is not defined"
     ]
    }
   ],
   "source": [
    "x_p=p_x.mean()\n",
    "np_x= sess.run(x_p,{y:np_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d85b937-8ea5-402d-b863-ac0fb34eb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y = np_y.reshape((10,10,N,K))\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=0),axis=3)\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=1),axis=2)\n",
    "y_img = np.squeeze(np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9343f6f-552c-4a35-869f-85d5930dbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x = np_x.reshape((10,10,28,28))\n",
    "# split into 10 (1,10,28,28) images, concat along columns -> 1,10,28,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=0),axis=3)\n",
    "# split into 10 (1,1,28,280) images, concat along rows -> 1,1,280,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=1),axis=2)\n",
    "x_img = np.squeeze(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeec9d-2a70-4159-962f-4c7a2e677b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2,figsize=(15,15))\n",
    "# samples\n",
    "axarr[0].matshow(y_img,cmap=plt.cm.gray)\n",
    "axarr[0].set_title('Z Samples')\n",
    "# reconstruction\n",
    "axarr[1].imshow(x_img,cmap=plt.cm.gray,interpolation='none')\n",
    "axarr[1].set_title('Generated Images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
