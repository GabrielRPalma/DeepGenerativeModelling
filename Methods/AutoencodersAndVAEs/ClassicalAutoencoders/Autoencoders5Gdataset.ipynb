{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c1a3a6",
   "metadata": {},
   "source": [
    "# Auto encoders \n",
    "\n",
    "Author: Gabriel Rodrigues Palma\n",
    "\n",
    "additional source: DataCamp and MIT introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577d69a",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4e8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from keract import get_activations, display_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c20518d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41eb3e",
   "metadata": {},
   "source": [
    "# Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eda2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToBinary(data):\n",
    "    reshapedData = np.array(data).reshape(len(data), -1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(reshapedData)    \n",
    "    return(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ef97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_encodings(encoded_imgs,number=1):\n",
    "    n = 5  # how many digits we will display\n",
    "    original = X_test\n",
    "    original = original[np.where(y_test == number)]\n",
    "    encoded_imgs = encoded_imgs[np.where(y_test==number)]\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    #plt.title('Original '+str(number)+' vs Encoded representation')\n",
    "    for i in range(min(n,len(original))):\n",
    "        # display original imgs\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(original[i].reshape(2, 5))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display encoded imgs\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(np.tile(encoded_imgs[i],(32,1)))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def compare_plot(original,decoded_imgs):\n",
    "    n = 4  # How many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # Display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(original[i].reshape(2, 5))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # Display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(2, 5))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.title('Real vs Decoded images')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f13265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe549241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 5\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed12dfa",
   "metadata": {},
   "source": [
    "## Loading the data and visualizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e703ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/5G-production-dataset/Download/Static/B_2019.12.16_13.40.04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc88f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_data = transformToBinary(data['PINGMAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64b817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.00000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.999067</td>\n",
       "      <td>-13.856276</td>\n",
       "      <td>3.717219</td>\n",
       "      <td>10.65329</td>\n",
       "      <td>50382.109193</td>\n",
       "      <td>141.879608</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221694e-07</td>\n",
       "      <td>9.162706e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>2.239170</td>\n",
       "      <td>3.260739</td>\n",
       "      <td>1.91965</td>\n",
       "      <td>65620.519457</td>\n",
       "      <td>122.211380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3229.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>23853.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>61175.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.394624e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-93.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>302694.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Longitude      Latitude   Speed  CellID         RSRP         RSRQ  \\\n",
       "count  2.143000e+03  2.143000e+03  2143.0  2143.0  2143.000000  2143.000000   \n",
       "mean  -8.394628e+00  5.188614e+01     0.0    11.0   -95.999067   -13.856276   \n",
       "std    1.221694e-07  9.162706e-08     0.0     0.0     1.274617     2.239170   \n",
       "min   -8.394628e+00  5.188614e+01     0.0    11.0  -104.000000   -19.000000   \n",
       "25%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -16.000000   \n",
       "50%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -14.000000   \n",
       "75%   -8.394628e+00  5.188614e+01     0.0    11.0   -95.000000   -12.000000   \n",
       "max   -8.394624e+00  5.188614e+01     0.0    11.0   -93.000000    -9.000000   \n",
       "\n",
       "               SNR         CQI     DL_bitrate   UL_bitrate   RAWCELLID  \n",
       "count  2143.000000  2143.00000    2143.000000  2143.000000      2143.0  \n",
       "mean      3.717219    10.65329   50382.109193   141.879608  10805003.0  \n",
       "std       3.260739     1.91965   65620.519457   122.211380         0.0  \n",
       "min      -7.000000     6.00000       0.000000     0.000000  10805003.0  \n",
       "25%       2.000000    10.00000    3229.500000    44.000000  10805003.0  \n",
       "50%       4.000000    11.00000   23853.000000   128.000000  10805003.0  \n",
       "75%       6.000000    11.00000   61175.000000   215.000000  10805003.0  \n",
       "max      15.000000    15.00000  302694.000000  1215.000000  10805003.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff7e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['CellID','RSRP','RSRQ','SNR','CQI','DL_bitrate','UL_bitrate','RAWCELLID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75564aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>-103</td>\n",
       "      <td>-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-102</td>\n",
       "      <td>-16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>-102</td>\n",
       "      <td>-16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>-102</td>\n",
       "      <td>-16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-104</td>\n",
       "      <td>-14</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>11</td>\n",
       "      <td>-98</td>\n",
       "      <td>-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>242467</td>\n",
       "      <td>311</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>11</td>\n",
       "      <td>-98</td>\n",
       "      <td>-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>214448</td>\n",
       "      <td>247</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>11</td>\n",
       "      <td>-99</td>\n",
       "      <td>-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>246969</td>\n",
       "      <td>228</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>11</td>\n",
       "      <td>-99</td>\n",
       "      <td>-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>251152</td>\n",
       "      <td>252</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>11</td>\n",
       "      <td>-100</td>\n",
       "      <td>-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>75422</td>\n",
       "      <td>87</td>\n",
       "      <td>10805003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CellID  RSRP  RSRQ  SNR  CQI  DL_bitrate  UL_bitrate  RAWCELLID\n",
       "0         11  -103   -15  1.0   15          72          20   10805003\n",
       "1         11  -102   -16  7.0   15           0           0   10805003\n",
       "2         11  -102   -16  7.0   15           0           0   10805003\n",
       "3         11  -102   -16  7.0   15           0           0   10805003\n",
       "4         11  -104   -14 -7.0   11           0           0   10805003\n",
       "...      ...   ...   ...  ...  ...         ...         ...        ...\n",
       "2138      11   -98   -11  2.0   14      242467         311   10805003\n",
       "2139      11   -98   -11  2.0   14      214448         247   10805003\n",
       "2140      11   -99   -13  8.0    8      246969         228   10805003\n",
       "2141      11   -99   -13  8.0    8      251152         252   10805003\n",
       "2142      11  -100   -14  0.0    9       75422          87   10805003\n",
       "\n",
       "[2143 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e51564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = minmax_scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25094cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1deb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((data, encoded_text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f8fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2143, 42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5677e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70842fec",
   "metadata": {},
   "source": [
    "## Implementing auto encoders with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d807019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 30)                1290      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 20)                620       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                60        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 30)                630       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 42)                1302      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,387\n",
      "Trainable params: 4,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(30, input_shape=(42, ), activation=\"relu\"))\n",
    "autoencoder.add(Dense(20, input_shape=(42, ), activation=\"relu\"))\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(42, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(30, input_shape=(42, ), activation=\"relu\"))\n",
    "autoencoder.add(Dense(20, activation=\"relu\"))\n",
    "autoencoder.add(Dense(10, activation=\"relu\"))\n",
    "autoencoder.add(Dense(5, activation=\"relu\"))\n",
    "autoencoder.add(Dropout(0.7))\n",
    "autoencoder.add(Dense(10, activation=\"relu\"))\n",
    "autoencoder.add(Dense(20, activation=\"relu\"))\n",
    "autoencoder.add(Dense(30, activation=\"relu\"))\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(42, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cd18294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.72727273, 0.2       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.63636364, 0.3       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.72727273, 0.7       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.72727273, 0.7       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.81818182, 0.7       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.81818182, 0.4       , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9cb3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.8747\n",
      "Epoch 2/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.8747\n",
      "Epoch 3/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1315 - accuracy: 0.8747\n",
      "Epoch 4/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.8747\n",
      "Epoch 5/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.8747\n",
      "Epoch 6/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.8747\n",
      "Epoch 7/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.8747\n",
      "Epoch 8/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.8747\n",
      "Epoch 9/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.8747\n",
      "Epoch 10/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.8747\n",
      "Epoch 11/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1298 - accuracy: 0.8747\n",
      "Epoch 12/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.8747\n",
      "Epoch 13/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.8747\n",
      "Epoch 14/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.8747\n",
      "Epoch 15/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.8747\n",
      "Epoch 16/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.8747\n",
      "Epoch 17/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1285 - accuracy: 0.8747\n",
      "Epoch 18/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.8747\n",
      "Epoch 19/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.8747\n",
      "Epoch 20/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1286 - accuracy: 0.8747\n",
      "Epoch 21/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.8747\n",
      "Epoch 22/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.8747\n",
      "Epoch 23/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1285 - accuracy: 0.8747\n",
      "Epoch 24/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.8747\n",
      "Epoch 25/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.8747\n",
      "Epoch 26/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1285 - accuracy: 0.8747\n",
      "Epoch 27/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.8747\n",
      "Epoch 28/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.8747\n",
      "Epoch 29/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.8747\n",
      "Epoch 30/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.8747\n",
      "Epoch 31/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1289 - accuracy: 0.8747\n",
      "Epoch 32/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.8747\n",
      "Epoch 33/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.8747\n",
      "Epoch 34/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.8747\n",
      "Epoch 35/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.8747\n",
      "Epoch 36/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.8747\n",
      "Epoch 37/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.8747\n",
      "Epoch 38/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.8747\n",
      "Epoch 39/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.8747\n",
      "Epoch 40/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.8747\n",
      "Epoch 41/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.8747\n",
      "Epoch 42/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1255 - accuracy: 0.8747\n",
      "Epoch 43/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.8747\n",
      "Epoch 44/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.8747\n",
      "Epoch 45/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.8747\n",
      "Epoch 46/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.8747\n",
      "Epoch 47/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.8747\n",
      "Epoch 48/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.8747\n",
      "Epoch 49/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.8747\n",
      "Epoch 50/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.8747\n",
      "Epoch 51/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.8747\n",
      "Epoch 52/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1257 - accuracy: 0.8747\n",
      "Epoch 53/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.8747\n",
      "Epoch 54/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.8747\n",
      "Epoch 55/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.8747\n",
      "Epoch 56/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.8747\n",
      "Epoch 57/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.8747\n",
      "Epoch 58/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1258 - accuracy: 0.8747\n",
      "Epoch 59/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.8747\n",
      "Epoch 60/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.8747\n",
      "Epoch 61/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1239 - accuracy: 0.8747\n",
      "Epoch 62/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.8747\n",
      "Epoch 63/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.8747\n",
      "Epoch 64/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.8747\n",
      "Epoch 65/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.8747\n",
      "Epoch 66/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1239 - accuracy: 0.8747\n",
      "Epoch 67/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.8747\n",
      "Epoch 68/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1234 - accuracy: 0.8747\n",
      "Epoch 69/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.8747\n",
      "Epoch 70/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.8747\n",
      "Epoch 71/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.8747\n",
      "Epoch 72/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1233 - accuracy: 0.8747\n",
      "Epoch 73/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.8747\n",
      "Epoch 74/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1236 - accuracy: 0.8747\n",
      "Epoch 75/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.8747\n",
      "Epoch 76/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.8747\n",
      "Epoch 77/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.8747\n",
      "Epoch 78/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.8747\n",
      "Epoch 79/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.8747\n",
      "Epoch 80/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.8747\n",
      "Epoch 81/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.8747\n",
      "Epoch 82/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.8747\n",
      "Epoch 83/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.8747\n",
      "Epoch 84/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.8747\n",
      "Epoch 85/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.8747\n",
      "Epoch 86/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.8747\n",
      "Epoch 87/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.8747\n",
      "Epoch 88/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.8747\n",
      "Epoch 89/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.8747\n",
      "Epoch 90/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.8747\n",
      "Epoch 91/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.8747\n",
      "Epoch 92/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.8747\n",
      "Epoch 93/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.8747\n",
      "Epoch 94/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.8747\n",
      "Epoch 95/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.8747\n",
      "Epoch 96/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.8747\n",
      "Epoch 97/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.8747\n",
      "Epoch 98/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.8747\n",
      "Epoch 99/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.8747\n",
      "Epoch 100/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.8747\n",
      "Epoch 101/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.8747\n",
      "Epoch 102/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.8747\n",
      "Epoch 103/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.8747\n",
      "Epoch 104/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1210 - accuracy: 0.8747\n",
      "Epoch 105/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.8747\n",
      "Epoch 106/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.8747\n",
      "Epoch 107/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.8747\n",
      "Epoch 108/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.8747\n",
      "Epoch 109/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.8747\n",
      "Epoch 110/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1204 - accuracy: 0.8747\n",
      "Epoch 111/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.8747\n",
      "Epoch 112/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.8747\n",
      "Epoch 113/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.8747\n",
      "Epoch 114/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.8747\n",
      "Epoch 115/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.8747\n",
      "Epoch 116/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.8747\n",
      "Epoch 117/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.8747\n",
      "Epoch 118/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.8747\n",
      "Epoch 119/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.8747\n",
      "Epoch 120/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.8747\n",
      "Epoch 121/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.8747\n",
      "Epoch 122/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.8747\n",
      "Epoch 123/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.8747\n",
      "Epoch 124/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.8747\n",
      "Epoch 125/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.8747\n",
      "Epoch 126/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.8747\n",
      "Epoch 127/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.8747\n",
      "Epoch 128/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.8747\n",
      "Epoch 129/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.8747\n",
      "Epoch 130/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.8747\n",
      "Epoch 131/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.8747\n",
      "Epoch 132/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.8747\n",
      "Epoch 133/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.8747\n",
      "Epoch 134/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.8747\n",
      "Epoch 135/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8747\n",
      "Epoch 136/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.8747\n",
      "Epoch 137/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.8747\n",
      "Epoch 138/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.8747\n",
      "Epoch 139/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.8747\n",
      "Epoch 140/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.8747\n",
      "Epoch 141/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8747\n",
      "Epoch 142/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8747\n",
      "Epoch 143/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8747\n",
      "Epoch 144/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.8747\n",
      "Epoch 145/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.8747\n",
      "Epoch 146/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.8747\n",
      "Epoch 147/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.8747\n",
      "Epoch 148/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.8747\n",
      "Epoch 149/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.8747\n",
      "Epoch 150/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.8747\n",
      "Epoch 151/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.8747\n",
      "Epoch 152/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.8747\n",
      "Epoch 153/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.8747\n",
      "Epoch 154/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.8747\n",
      "Epoch 155/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.8747\n",
      "Epoch 156/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.8747\n",
      "Epoch 157/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.8747\n",
      "Epoch 158/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.8747\n",
      "Epoch 159/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.8747\n",
      "Epoch 160/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.8747\n",
      "Epoch 161/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.8747\n",
      "Epoch 162/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.8747\n",
      "Epoch 163/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.8747\n",
      "Epoch 164/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.8747\n",
      "Epoch 165/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.8747\n",
      "Epoch 166/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.8747\n",
      "Epoch 167/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.8747\n",
      "Epoch 168/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.8747\n",
      "Epoch 169/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.8747\n",
      "Epoch 170/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.8747\n",
      "Epoch 171/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.8747\n",
      "Epoch 172/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.8747\n",
      "Epoch 173/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.8747\n",
      "Epoch 174/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.8747\n",
      "Epoch 175/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.8747\n",
      "Epoch 176/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.8747\n",
      "Epoch 177/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.8747\n",
      "Epoch 178/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.8747\n",
      "Epoch 179/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.8747\n",
      "Epoch 180/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.8747\n",
      "Epoch 181/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.8747\n",
      "Epoch 182/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.8747\n",
      "Epoch 183/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.8747\n",
      "Epoch 184/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.8747\n",
      "Epoch 185/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 186/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.8747\n",
      "Epoch 187/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.8747\n",
      "Epoch 188/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.8747\n",
      "Epoch 189/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.8747\n",
      "Epoch 190/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.8747\n",
      "Epoch 191/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.8747\n",
      "Epoch 192/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.8747\n",
      "Epoch 193/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.8747\n",
      "Epoch 194/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 195/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 196/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.8747\n",
      "Epoch 197/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.8747\n",
      "Epoch 198/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.8747\n",
      "Epoch 199/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.8747\n",
      "Epoch 200/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.8747\n",
      "Epoch 201/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.8747\n",
      "Epoch 202/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.8747\n",
      "Epoch 203/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 204/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.8747\n",
      "Epoch 205/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.8747\n",
      "Epoch 206/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.8747\n",
      "Epoch 207/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 208/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.8747\n",
      "Epoch 209/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.8747\n",
      "Epoch 210/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.8747\n",
      "Epoch 211/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.8747\n",
      "Epoch 212/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.8747\n",
      "Epoch 213/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.8747\n",
      "Epoch 214/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1139 - accuracy: 0.8747\n",
      "Epoch 215/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.8747\n",
      "Epoch 216/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.8747\n",
      "Epoch 217/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.8747\n",
      "Epoch 218/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.8747\n",
      "Epoch 219/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1137 - accuracy: 0.8747\n",
      "Epoch 220/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1139 - accuracy: 0.8747\n",
      "Epoch 221/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1139 - accuracy: 0.8747\n",
      "Epoch 222/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.8747\n",
      "Epoch 223/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1133 - accuracy: 0.8747\n",
      "Epoch 224/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.8747\n",
      "Epoch 225/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1132 - accuracy: 0.8747\n",
      "Epoch 226/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1131 - accuracy: 0.8747\n",
      "Epoch 227/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.8747\n",
      "Epoch 228/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.8747\n",
      "Epoch 229/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1131 - accuracy: 0.8747\n",
      "Epoch 230/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.8747\n",
      "Epoch 231/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.8747\n",
      "Epoch 232/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.8747\n",
      "Epoch 233/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.8747\n",
      "Epoch 234/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.8747\n",
      "Epoch 235/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.8747\n",
      "Epoch 236/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.8747\n",
      "Epoch 237/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.8747\n",
      "Epoch 238/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.8747\n",
      "Epoch 239/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.8747\n",
      "Epoch 240/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.8747\n",
      "Epoch 241/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.8747\n",
      "Epoch 242/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.8747\n",
      "Epoch 243/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.8747\n",
      "Epoch 244/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.8747\n",
      "Epoch 245/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8747\n",
      "Epoch 246/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.8747\n",
      "Epoch 247/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.8747\n",
      "Epoch 248/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.8747\n",
      "Epoch 249/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.8747\n",
      "Epoch 250/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.8747\n",
      "Epoch 251/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.8747\n",
      "Epoch 252/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.8747\n",
      "Epoch 253/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.8747\n",
      "Epoch 254/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.8747\n",
      "Epoch 255/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.8747\n",
      "Epoch 256/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8747\n",
      "Epoch 257/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.8747\n",
      "Epoch 258/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.8747\n",
      "Epoch 259/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8747\n",
      "Epoch 260/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.8747\n",
      "Epoch 261/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8747\n",
      "Epoch 262/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.8747\n",
      "Epoch 263/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8747\n",
      "Epoch 264/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8747\n",
      "Epoch 265/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.8747\n",
      "Epoch 266/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8747\n",
      "Epoch 267/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.8747\n",
      "Epoch 268/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.8747\n",
      "Epoch 269/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.8747\n",
      "Epoch 270/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8747\n",
      "Epoch 271/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.8747\n",
      "Epoch 272/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.8747\n",
      "Epoch 273/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.8747\n",
      "Epoch 274/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.8747\n",
      "Epoch 275/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.8747\n",
      "Epoch 276/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 277/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 278/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8747\n",
      "Epoch 279/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8747\n",
      "Epoch 280/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.8747\n",
      "Epoch 281/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8747\n",
      "Epoch 282/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.8747\n",
      "Epoch 283/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8747\n",
      "Epoch 284/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.8747\n",
      "Epoch 285/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8747\n",
      "Epoch 286/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8747\n",
      "Epoch 287/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.8747\n",
      "Epoch 288/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8747\n",
      "Epoch 289/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8747\n",
      "Epoch 290/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8747\n",
      "Epoch 291/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8747\n",
      "Epoch 292/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.8747\n",
      "Epoch 293/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8747\n",
      "Epoch 294/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8747\n",
      "Epoch 295/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 296/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.8747\n",
      "Epoch 297/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8747\n",
      "Epoch 298/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 299/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 300/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.8747\n",
      "Epoch 301/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.8747\n",
      "Epoch 302/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.8747\n",
      "Epoch 303/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.8747\n",
      "Epoch 304/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.8747\n",
      "Epoch 305/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.8747\n",
      "Epoch 306/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8747\n",
      "Epoch 307/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.8747\n",
      "Epoch 308/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8747\n",
      "Epoch 309/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8747\n",
      "Epoch 310/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.8747\n",
      "Epoch 311/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8747\n",
      "Epoch 312/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.8747\n",
      "Epoch 313/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.8747\n",
      "Epoch 314/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.8747\n",
      "Epoch 315/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.8747\n",
      "Epoch 316/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 317/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.8747\n",
      "Epoch 318/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.8747\n",
      "Epoch 319/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.8747\n",
      "Epoch 320/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.8747\n",
      "Epoch 321/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.8747\n",
      "Epoch 322/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 323/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.8747\n",
      "Epoch 324/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 325/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8747\n",
      "Epoch 326/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8747\n",
      "Epoch 327/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 328/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8747\n",
      "Epoch 329/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 330/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 331/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.8747\n",
      "Epoch 332/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 333/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 334/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 335/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.8747\n",
      "Epoch 336/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.8747\n",
      "Epoch 337/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.8747\n",
      "Epoch 338/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.8747\n",
      "Epoch 339/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 340/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.8747\n",
      "Epoch 341/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 342/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 343/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.8747\n",
      "Epoch 344/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 345/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.8747\n",
      "Epoch 346/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.8747\n",
      "Epoch 347/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.8747\n",
      "Epoch 348/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 349/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 350/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8747\n",
      "Epoch 351/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 352/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 353/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.8747\n",
      "Epoch 354/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.8747\n",
      "Epoch 355/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.8747\n",
      "Epoch 356/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.8747\n",
      "Epoch 357/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 358/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8747\n",
      "Epoch 359/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8747\n",
      "Epoch 360/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.8747\n",
      "Epoch 361/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 362/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 363/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8747\n",
      "Epoch 364/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 365/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 366/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.8747\n",
      "Epoch 367/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.8747\n",
      "Epoch 368/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.8747\n",
      "Epoch 369/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.8747\n",
      "Epoch 370/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 371/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8747\n",
      "Epoch 372/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.8747\n",
      "Epoch 373/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.8747\n",
      "Epoch 374/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.8747\n",
      "Epoch 375/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.8747\n",
      "Epoch 376/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8747\n",
      "Epoch 377/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.8747\n",
      "Epoch 378/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.8747\n",
      "Epoch 379/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.8747\n",
      "Epoch 380/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.8747\n",
      "Epoch 381/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 382/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.8747\n",
      "Epoch 383/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8747\n",
      "Epoch 384/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8747\n",
      "Epoch 385/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 386/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.8747\n",
      "Epoch 387/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.8747\n",
      "Epoch 388/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 389/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 390/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.8747\n",
      "Epoch 391/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.8747\n",
      "Epoch 392/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.8747\n",
      "Epoch 393/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8747\n",
      "Epoch 394/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.8747\n",
      "Epoch 395/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.8747\n",
      "Epoch 396/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8747\n",
      "Epoch 397/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8747\n",
      "Epoch 398/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.8747\n",
      "Epoch 399/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8747\n",
      "Epoch 400/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.8747\n",
      "Epoch 401/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 402/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 403/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 404/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8747\n",
      "Epoch 405/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 406/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8747\n",
      "Epoch 407/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 408/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.8747\n",
      "Epoch 409/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.8747\n",
      "Epoch 410/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.8747\n",
      "Epoch 411/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.8747\n",
      "Epoch 412/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 413/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.8747\n",
      "Epoch 414/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 415/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 416/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.8747\n",
      "Epoch 417/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 418/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 419/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 420/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.8747\n",
      "Epoch 421/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8747\n",
      "Epoch 422/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 423/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8747\n",
      "Epoch 424/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8747\n",
      "Epoch 425/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 426/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 427/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 428/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.8747\n",
      "Epoch 429/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.8747\n",
      "Epoch 430/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 431/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8747\n",
      "Epoch 432/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.8747\n",
      "Epoch 433/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 434/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.8747\n",
      "Epoch 435/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 436/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 437/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.8747\n",
      "Epoch 438/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 439/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8747\n",
      "Epoch 440/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 441/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8747\n",
      "Epoch 442/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8747\n",
      "Epoch 443/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 444/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 445/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 446/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 447/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.8747\n",
      "Epoch 448/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 449/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 450/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.8747\n",
      "Epoch 451/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 452/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.8747\n",
      "Epoch 453/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 454/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 455/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 456/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 457/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 458/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 459/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8747\n",
      "Epoch 460/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 461/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 462/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 463/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 464/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.8747\n",
      "Epoch 465/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 466/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 467/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 468/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 469/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 470/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 471/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 472/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 473/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.8747\n",
      "Epoch 474/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 475/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 476/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 477/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 478/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 479/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 480/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8747\n",
      "Epoch 481/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 482/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8747\n",
      "Epoch 483/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 484/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 485/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 486/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 487/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 488/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 489/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 490/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.8747\n",
      "Epoch 491/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 492/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 493/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 494/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 495/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 496/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 497/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 498/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.8747\n",
      "Epoch 499/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 500/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 501/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 502/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 503/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 504/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 505/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 506/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.8747\n",
      "Epoch 507/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 508/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.8747\n",
      "Epoch 509/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 510/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8747\n",
      "Epoch 511/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8747\n",
      "Epoch 512/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 513/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.8747\n",
      "Epoch 514/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 515/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 516/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 517/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 518/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8747\n",
      "Epoch 519/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 520/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 521/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 522/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 523/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.8747\n",
      "Epoch 524/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8747\n",
      "Epoch 525/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 526/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 527/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 528/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.8747\n",
      "Epoch 529/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.8747\n",
      "Epoch 530/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 531/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 532/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 533/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 534/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 535/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 536/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 537/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 538/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 539/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 540/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.8747\n",
      "Epoch 541/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 542/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8747\n",
      "Epoch 543/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 544/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 545/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 546/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 547/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 548/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.8747\n",
      "Epoch 549/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 550/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 551/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 552/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.8747\n",
      "Epoch 553/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 554/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 555/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 556/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 557/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 558/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 559/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 560/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 561/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 562/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 563/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 564/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 565/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8747\n",
      "Epoch 566/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 567/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 568/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 569/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 570/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 571/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 572/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.8747\n",
      "Epoch 573/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 574/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 575/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8747\n",
      "Epoch 576/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 577/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 578/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 579/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8747\n",
      "Epoch 580/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 581/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 582/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 583/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 584/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 585/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.8747\n",
      "Epoch 586/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 587/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8747\n",
      "Epoch 588/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 589/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.8747\n",
      "Epoch 590/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 591/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8747\n",
      "Epoch 592/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 593/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 594/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.8747\n",
      "Epoch 595/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 596/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.8747\n",
      "Epoch 597/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.8747\n",
      "Epoch 598/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 599/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 600/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 601/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 602/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 603/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 604/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 605/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 606/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 607/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 608/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 609/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 610/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 611/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 612/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 613/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 614/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 615/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 616/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 617/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 618/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 619/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 620/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 621/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 622/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 623/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 624/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 625/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 626/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 627/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8747\n",
      "Epoch 628/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 629/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 630/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 631/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.8747\n",
      "Epoch 632/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 633/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8747\n",
      "Epoch 634/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 635/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 636/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.8747\n",
      "Epoch 637/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 638/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 639/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 640/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 641/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 642/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8747\n",
      "Epoch 643/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 644/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 645/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 646/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 647/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 648/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 649/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 650/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 651/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 652/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 653/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 654/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 655/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 656/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 657/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 658/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 659/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 660/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 661/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8747\n",
      "Epoch 662/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 663/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 664/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 665/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 666/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 667/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 668/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 669/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 670/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.8747\n",
      "Epoch 671/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 672/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 673/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 674/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 675/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 676/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 677/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 678/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 679/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 680/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 681/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 682/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 683/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 684/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 685/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 686/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 687/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 688/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 689/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 690/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 691/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 692/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 693/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.8747\n",
      "Epoch 694/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 695/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 696/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 697/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 698/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.8747\n",
      "Epoch 699/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 700/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.8747\n",
      "Epoch 701/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 702/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 703/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 704/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 705/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 706/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 707/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.8747\n",
      "Epoch 708/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 709/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 710/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 711/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 712/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 713/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 714/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 715/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 716/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 717/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 718/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 719/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 720/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 721/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 722/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 723/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 724/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 725/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 726/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 727/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 728/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 729/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 730/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 731/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 732/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.8747\n",
      "Epoch 733/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 734/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 735/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 736/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 737/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 738/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 739/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 740/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 741/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 742/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 743/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 744/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 745/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 746/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 747/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.8747\n",
      "Epoch 748/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 749/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8747\n",
      "Epoch 750/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 751/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 752/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 753/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 754/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 755/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 756/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 757/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 758/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8747\n",
      "Epoch 759/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 760/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 761/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 762/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 763/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 764/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 765/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 766/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 767/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 768/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 769/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 770/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 771/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 772/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 773/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8747\n",
      "Epoch 774/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 775/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 776/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 777/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 778/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 779/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 780/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 781/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 782/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 783/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 784/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 785/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 786/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 787/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 788/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 789/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 790/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 791/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 792/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 793/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 794/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 795/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 796/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 797/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 798/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 799/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 800/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 801/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 802/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 803/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.8747\n",
      "Epoch 804/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 805/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 806/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 807/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 808/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 809/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 810/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 811/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 812/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 813/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 814/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 815/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 816/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 817/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 818/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 819/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 820/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 821/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 822/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 823/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 824/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 825/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 826/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 827/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 828/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 829/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 830/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 831/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 832/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 833/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 834/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.8747\n",
      "Epoch 835/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.8747\n",
      "Epoch 836/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 837/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 838/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 839/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 840/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 841/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 842/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 843/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.8747\n",
      "Epoch 844/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 845/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 846/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 847/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.8747\n",
      "Epoch 848/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 849/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 850/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 851/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 852/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 853/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 854/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 855/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 856/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 857/1000\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 858/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 859/1000\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 860/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 861/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 862/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 863/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 864/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 865/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 866/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 867/1000\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 868/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 869/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 870/1000\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 871/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 872/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 873/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 874/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 875/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 876/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 877/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 878/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 879/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 880/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 881/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 882/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 883/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 884/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 885/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.8747\n",
      "Epoch 886/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 887/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 888/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 889/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 890/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 891/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 892/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 893/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 894/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 895/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 896/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.8747\n",
      "Epoch 897/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 898/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 899/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 900/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 901/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 902/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 903/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 904/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 905/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 906/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 907/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 908/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 909/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 910/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 911/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 912/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 913/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 914/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 915/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 916/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 917/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 918/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 919/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 920/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 921/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 922/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 923/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 924/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 925/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 926/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 927/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 928/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 929/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 930/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 931/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 932/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 933/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 934/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 935/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 936/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.8747\n",
      "Epoch 937/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 938/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 939/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 940/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 941/1000\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 942/1000\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 943/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 944/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.8747\n",
      "Epoch 945/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 946/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 947/1000\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1025 - accuracy: 0.8747\n",
      "Epoch 948/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.8747\n",
      "Epoch 949/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 950/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 951/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 952/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 953/1000\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 954/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 955/1000\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 956/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.8747\n",
      "Epoch 957/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 958/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 959/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 960/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 961/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 962/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 963/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 964/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 965/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 966/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 967/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 968/1000\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 969/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 970/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 971/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 972/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.8747\n",
      "Epoch 973/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 974/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.8747\n",
      "Epoch 975/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.8747\n",
      "Epoch 976/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 977/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 978/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.8747\n",
      "Epoch 979/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 980/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 981/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.8747\n",
      "Epoch 982/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 983/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 984/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 985/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.8747\n",
      "Epoch 986/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.8747\n",
      "Epoch 987/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 988/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 989/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.8747\n",
      "Epoch 990/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 991/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 992/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 993/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 994/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.8747\n",
      "Epoch 995/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 996/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8747\n",
      "Epoch 997/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8747\n",
      "Epoch 998/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 999/1000\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8747\n",
      "Epoch 1000/1000\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.8747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2968aea60>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "autoencoder.fit(X_train, X_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26965aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_accuracy = pd.DataFrame(autoencoder.history.history['accuracy'])\n",
    "autoencoder_loss = pd.DataFrame(autoencoder.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa3adad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(autoencoder_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8db31754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(autoencoder_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8196080",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_accuracy.to_csv('../../Results/5GdatasetAutoencoderAccuracy.csv')\n",
    "autoencoder_loss.to_csv('../../Results/5GdatasetAutoencoderLoss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d96df9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.save_weights('autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3218b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 15:45:42.691966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_train)\n",
    "#show_encodings(encodings, number = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c827476",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings.shape\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_imgs = autoencoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "501e6fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 42)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a54798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        , -414.36363636, -676.8       ,  653.63636364,\n",
       "       -716.22222222,  257.63878372,  176.22469136,    0.        ,\n",
       "       -110.        ,    1.        ,    1.        ,    2.        ,\n",
       "          1.        ,    0.        ,    0.        ,    1.        ,\n",
       "          2.        ,    1.        ,    0.        ,    1.        ,\n",
       "          0.        ,    0.        ,    1.        ,    1.        ,\n",
       "          0.        ,    1.        ,    2.        ,   14.        ,\n",
       "         17.        ,   18.        ,    8.        ,    7.        ,\n",
       "          4.        ,    5.        ,   11.        ,    4.        ,\n",
       "          2.        ,    1.        ,    1.        ,    1.        ,\n",
       "          1.        ,    1.        ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_train -np.round(decoded_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d6cdb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 42)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "X_test[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b742a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "activations = get_activations(autoencoder, X_test[0:1])\n",
    "subset = lambda d, *keys: [(key, d[key]) for key in d.keys() if key in set(keys)]\n",
    "new_set = collections.OrderedDict(subset(activations, 'dense_input', 'dense_1', 'dense_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa354f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.72727273 0.2        0.45454545 0.22222222 0.05013644\n",
      "  0.0872428  0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n",
      "[[0.00181916 0.706796   0.5307429  0.48813263 0.5152505  0.19549532\n",
      "  0.13828968 0.00328991 0.9420802  0.00332182 0.00154548 0.00332439\n",
      "  0.00247643 0.00266394 0.00226763 0.00284835 0.00304987 0.00275831\n",
      "  0.00161607 0.00290346 0.0027505  0.00183822 0.00330875 0.00371225\n",
      "  0.00303671 0.00373915 0.00222593 0.00726009 0.00936668 0.00235595\n",
      "  0.0044457  0.00143241 0.00408051 0.00421041 0.0047483  0.00444333\n",
      "  0.00241996 0.00329562 0.00190116 0.00253728 0.00309774 0.00308174]]\n"
     ]
    }
   ],
   "source": [
    "print(activations['dense_input'])\n",
    "print(activations['dense_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> Encoded \n",
    "# Encoded CSV\n",
    "# output as a CSV  \n",
    "def return_orinal_data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e19dba62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_input (1, 42) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 (1, 20) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2 (1, 42) \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_activations(new_set, cmap=\"gray\", save=False, directory='../../Results/Plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601c30e",
   "metadata": {},
   "source": [
    "# Implementing Variational Auto Encoders with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8105df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffed7f6",
   "metadata": {},
   "source": [
    "## Creating the VA autoencoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f004695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Changing the image size\n",
    "X_train_new = X_train.reshape(1500, 2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5608a",
   "metadata": {},
   "source": [
    "#### Build the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09b19128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 2, 5, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 1, 3, 32)     160         ['input_37[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 1, 2, 64)     8256        ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 128)          0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 16)           2064        ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            34          ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            34          ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_10 (Sampling)         (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,548\n",
      "Trainable params: 10,548\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(2, 5, 1))\n",
    "x = layers.Conv2D(32, 2, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18138d6",
   "metadata": {},
   "source": [
    "#### Build the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef12575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 640)               1920      \n",
      "                                                                 \n",
      " reshape_20 (Reshape)        (None, 2, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_33 (Conv2D  (None, 2, 5, 64)         4160      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_34 (Conv2D  (None, 2, 5, 1)          65        \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,145\n",
      "Trainable params: 6,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(2 * 5 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((2, 5, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 1, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 1, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b789cc",
   "metadata": {},
   "source": [
    "## Define the VAE as a Model with a custom train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e30cace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c24c0",
   "metadata": {},
   "source": [
    "## Training the models with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22bc3ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 2, 5)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48038219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae = VAE(encoder, decoder)\n",
    "# vae.compile(optimizer=keras.optimizers.Adam())\n",
    "# vae.fit(X_train_new, epochs=30, batch_size=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff6e61",
   "metadata": {},
   "source": [
    "## Plotting the Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6bae2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2da39fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
