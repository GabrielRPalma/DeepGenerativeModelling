{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846cbd4a-806d-422c-8d02-53e470fad098",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (Encoding/Decoding) using Auto Encoders\n",
    "#### Contractive autoencoders\n",
    "Author: Gabriel Rodrigues Palma\n",
    "\n",
    "Purpose: Encode and decode 5G data. Also, generate new dasets based on the autoencoders methods.\n",
    "\n",
    "Sourcers: Contractive autoencoders code based on the paper: \n",
    "\n",
    "$\\textbf{Contractive Auto-Encoders: Explicit Invariance During Feature Extraction}$ \n",
    "\n",
    "$\\textit{Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, and Yoshua Bengio. Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, pages 833–840, USA, 2011. Omnipress.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efc5f6-4dd1-42db-8cdd-71f3847a9530",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41a0b28-aec9-474b-8fbf-85b407a2ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# visualisation modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keract import get_activations, display_activations\n",
    "\n",
    "# Deep learning modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Additional packages\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Testing GPU from MacOs\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f3b00-64de-4a26-9422-26ec9aaa0730",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "870b01b1-443e-42d7-ba61-475a4e015eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformCategoricalToBinary(data):\n",
    "    '''Function created to transform categorical data to binary arrays'''\n",
    "    reshapedData = np.array(data).reshape(len(data), -1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(reshapedData)    \n",
    "    return(onehot_encoded)\n",
    "\n",
    "def transformBinaryToCategorical(data, query):\n",
    "    '''Function created to transform binary arrays data to categorical'''\n",
    "    reshapedData = np.array(data).reshape(len(data), -1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(reshapedData)   \n",
    "    query = query\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(list(np.unique(reshapedData)))\n",
    "    inverted = label_encoder.inverse_transform(list(np.argmax(query, axis=1))) \n",
    "    return(inverted)\n",
    "\n",
    "def transformScaledToNonscaled(data, query):\n",
    "    '''Function to obtain original data from scaled one'''\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaled_data = scaler.fit_transform(data) \n",
    "    if query.ndim ==1:\n",
    "        query = query.reshape(1, len(query))\n",
    "    else:\n",
    "        query = query.reshape(len(query), -1)\n",
    "    result = scaler.inverse_transform(query)\n",
    "\n",
    "    return(result)\n",
    "\n",
    "def getOriginalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_numerical_data = decoded_data[:, 0:8]\n",
    "    decoded_categorical_data = np.round(decoded_data[:, 8:42])\n",
    "    numerical_data = transformScaledToNonscaled(data = original_data, \n",
    "                                                query = decoded_numerical_data)\n",
    "    categorical_data = transformBinaryToCategorical(data = categorical_data, \n",
    "                                                    query = decoded_categorical_data)    \n",
    "    result = np.hstack((numerical_data, categorical_data.reshape(len(categorical_data), 1)))\n",
    "\n",
    "    return(result)\n",
    "def getOriginalNumericalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_numerical_data = decoded_data   \n",
    "    numerical_data = transformScaledToNonscaled(data = original_data, \n",
    "                                                query = decoded_numerical_data)\n",
    "    result = numerical_data\n",
    "\n",
    "    return(result)\n",
    "def getOriginalCategoricalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_categorical_data = np.round(decoded_data)\n",
    "    categorical_data = transformBinaryToCategorical(data = categorical_data, \n",
    "                                                    query = decoded_categorical_data)  \n",
    "    result = numerical_data\n",
    "\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d8c72-fa55-427b-9b2f-51f98f854f44",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f7dc15-955a-465f-b3b2-22ab3dad29b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.00000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.999067</td>\n",
       "      <td>-13.856276</td>\n",
       "      <td>3.717219</td>\n",
       "      <td>10.65329</td>\n",
       "      <td>50382.109193</td>\n",
       "      <td>141.879608</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221694e-07</td>\n",
       "      <td>9.162706e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>2.239170</td>\n",
       "      <td>3.260739</td>\n",
       "      <td>1.91965</td>\n",
       "      <td>65620.519457</td>\n",
       "      <td>122.211380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3229.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>23853.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>61175.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.394624e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-93.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>302694.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Longitude      Latitude   Speed  CellID         RSRP         RSRQ  \\\n",
       "count  2.143000e+03  2.143000e+03  2143.0  2143.0  2143.000000  2143.000000   \n",
       "mean  -8.394628e+00  5.188614e+01     0.0    11.0   -95.999067   -13.856276   \n",
       "std    1.221694e-07  9.162706e-08     0.0     0.0     1.274617     2.239170   \n",
       "min   -8.394628e+00  5.188614e+01     0.0    11.0  -104.000000   -19.000000   \n",
       "25%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -16.000000   \n",
       "50%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -14.000000   \n",
       "75%   -8.394628e+00  5.188614e+01     0.0    11.0   -95.000000   -12.000000   \n",
       "max   -8.394624e+00  5.188614e+01     0.0    11.0   -93.000000    -9.000000   \n",
       "\n",
       "               SNR         CQI     DL_bitrate   UL_bitrate   RAWCELLID  \n",
       "count  2143.000000  2143.00000    2143.000000  2143.000000      2143.0  \n",
       "mean      3.717219    10.65329   50382.109193   141.879608  10805003.0  \n",
       "std       3.260739     1.91965   65620.519457   122.211380         0.0  \n",
       "min      -7.000000     6.00000       0.000000     0.000000  10805003.0  \n",
       "25%       2.000000    10.00000    3229.500000    44.000000  10805003.0  \n",
       "50%       4.000000    11.00000   23853.000000   128.000000  10805003.0  \n",
       "75%       6.000000    11.00000   61175.000000   215.000000  10805003.0  \n",
       "max      15.000000    15.00000  302694.000000  1215.000000  10805003.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv('../../../Data/5G-production-dataset/Download/Static/B_2019.12.16_13.40.04.csv')\n",
    "encoded_text_data = transformCategoricalToBinary(original_data['PINGMAX'])\n",
    "original_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c96ded8-edfa-4294-87ba-6ee460f49081",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_data_test = transformCategoricalToBinary(np.unique(original_data['PINGMAX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf82d1f-48f3-41ec-839d-634ec632cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = original_data[['CellID','RSRP','RSRQ','SNR','CQI','DL_bitrate','UL_bitrate','RAWCELLID']]\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(selected_data)\n",
    "data_scaled = scaler.transform(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a7ec34-6756-4640-bcf5-d326da83c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((data_scaled, encoded_text_data))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59112bae-d9f4-44d5-8540-0893a2adb75d",
   "metadata": {},
   "source": [
    "# Auto encoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe3b9d5-5e3f-450a-868e-b48ef5695e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 168       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,058\n",
      "Trainable params: 1,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 13:45:49.625582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-12 13:45:49.625810: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "lam = 0.01\n",
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(30, input_shape=(8, )))\n",
    "autoencoder.add(Dense(20, input_shape=(42, )))\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(8, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c932a5-2d60-42b1-aa4b-77ed2eb32cf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 13:45:55.084105: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-12 13:45:55.258143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 5ms/step - loss: 0.7569 - accuracy: 0.0100\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7563 - accuracy: 0.0100\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.0107\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7549 - accuracy: 0.0107\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.0107\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.0107\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.0107\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.0107\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.0107\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.0107\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.0107\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.0120\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7478 - accuracy: 0.0127\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7470 - accuracy: 0.0133\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7461 - accuracy: 0.0133\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.0140\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.0140\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7433 - accuracy: 0.0147\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.0147\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7414 - accuracy: 0.0153\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7405 - accuracy: 0.0153\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7395 - accuracy: 0.0160\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7385 - accuracy: 0.0160\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7375 - accuracy: 0.0167\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.0167\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7355 - accuracy: 0.0173\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.0187\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7334 - accuracy: 0.0193\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.0200\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7313 - accuracy: 0.0200\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7303 - accuracy: 0.0220\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7292 - accuracy: 0.0227\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.0233\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7271 - accuracy: 0.0247\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.0247\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7249 - accuracy: 0.0247\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7238 - accuracy: 0.0253\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7227 - accuracy: 0.0253\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.0260\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7205 - accuracy: 0.0260\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7194 - accuracy: 0.0273\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7183 - accuracy: 0.0273\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.0280\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.0287\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7149 - accuracy: 0.0307\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.0307\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.0313\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7115 - accuracy: 0.0340\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7104 - accuracy: 0.0353\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7092 - accuracy: 0.0373\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7081 - accuracy: 0.0407\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7069 - accuracy: 0.0427\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.0453\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7046 - accuracy: 0.0473\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.0520\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.0533\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7012 - accuracy: 0.0580\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7000 - accuracy: 0.0640\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.0667\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.0713\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.0740\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.0780\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.0807\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.0860\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.0927\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.0973\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.1060\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.1087\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.1133\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.1173\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.1207\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.1253\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.1300\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.1333\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.1340\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.1373\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.1400\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.1420\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.1433\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.1440\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.1473\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.1487\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.1500\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.1520\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.1527\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.1533\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.1533\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.1540\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.1567\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.1600\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.1600\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.1620\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.1640\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.1647\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.1647\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.1653\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.1660\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.1667\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.1673\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.1687\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.1693\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.1700\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.1700\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.1713\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.1720\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.1727\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.1760\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.1787\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.1787\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.1787\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.1793\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.1820\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.1833\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.1873\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.1887\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.1920\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.1953\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.1980\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6290 - accuracy: 0.2000\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.2007\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.2047\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.2093\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.2127\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.2140\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.2167\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.2173\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.2200\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.2213\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.2240\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.2253\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.2307\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.2333\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.2360\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.2400\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.2440\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.2473\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.2527\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.2560\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.2580\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.2633\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.2667\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.2707\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.2793\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6016 - accuracy: 0.2847\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.2887\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.2973\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.3007\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.3020\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.3067\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.3093\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.3200\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.3273\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.3347\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.3373\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.3460\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.3553\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.3647\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.3653\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.3693\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.3760\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.3807\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.3867\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.4000\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.4060\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.4133\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.4173\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.4247\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.4327\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.4420\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.4487\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.4507\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.4567\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5721 - accuracy: 0.4607\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.4647\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.4687\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.4720\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.4753\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5673 - accuracy: 0.4780\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.4847\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.4887\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.4907\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.4967\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.4953\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.4993\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.5040\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.5113\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.5140\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.5160\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.5153\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.5200\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.5193\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.5227\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.5287\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.5293\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.5300\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.5333\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.5353\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.5353\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.5360\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.5360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x284deabb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train[:, 0:8], X_train[:, 0:8], epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f17913-ad4b-4e50-bc82-98b2d79ceda9",
   "metadata": {},
   "source": [
    "## Obtaining numerical encoded and decoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f234aa56-5efe-45b1-b48f-547093fe2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 793us/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 14:08:41.805168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-12 14:08:41.896199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encoded_data = encoder.predict(X_train[:,0:8])\n",
    "\n",
    "#show_encodings(encodings, number = 1)\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_data = autoencoder.predict(X_train[:,0:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1cad75-3b4e-4527-a463-dd7d0944e4ec",
   "metadata": {},
   "source": [
    "# Showing autoencoder results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7d1ce-ed28-4a8e-8d7f-4562979c23d1",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1ff16c-5af1-4cb4-816a-6022f61487c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "      <th>PINGMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.99999999999999</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>2.9999999999999996</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61756.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>4.999999999999999</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25025.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.99999999999999</td>\n",
       "      <td>-12.000000000000002</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.000000000000002</td>\n",
       "      <td>6614.999999999999</td>\n",
       "      <td>27.999999999999996</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36005.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2.9999999999999996</td>\n",
       "      <td>10.000000000000002</td>\n",
       "      <td>36367.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.99999999999999</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.9999999999999993</td>\n",
       "      <td>11.0</td>\n",
       "      <td>195371.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.99999999999999</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>8.000000000000002</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.99999999999999</td>\n",
       "      <td>-12.000000000000002</td>\n",
       "      <td>4.999999999999999</td>\n",
       "      <td>10.000000000000002</td>\n",
       "      <td>31222.000000000004</td>\n",
       "      <td>138.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-12.000000000000002</td>\n",
       "      <td>1.0000000000000002</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10180.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>10.999999999999998</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10805003.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CellID                RSRP                 RSRQ                 SNR  \\\n",
       "0      11.0  -95.99999999999999                -17.0  2.9999999999999996   \n",
       "1      11.0               -97.0                -16.0   4.999999999999999   \n",
       "2      11.0  -95.99999999999999  -12.000000000000002                 7.0   \n",
       "3      11.0               -95.0                -15.0                 4.0   \n",
       "4      11.0               -95.0                -16.0  2.9999999999999996   \n",
       "...     ...                 ...                  ...                 ...   \n",
       "1495   11.0  -95.99999999999999                -15.0  1.9999999999999993   \n",
       "1496   11.0  -95.99999999999999                -16.0   8.000000000000002   \n",
       "1497   11.0  -95.99999999999999  -12.000000000000002   4.999999999999999   \n",
       "1498   11.0               -95.0  -12.000000000000002  1.0000000000000002   \n",
       "1499   11.0               -95.0                -15.0  10.999999999999998   \n",
       "\n",
       "                     CQI          DL_bitrate          UL_bitrate   RAWCELLID  \\\n",
       "0                    8.0             61756.0               256.0  10805003.0   \n",
       "1                    8.0             25025.0               145.0  10805003.0   \n",
       "2     10.000000000000002   6614.999999999999  27.999999999999996  10805003.0   \n",
       "3                   11.0             36005.0               149.0  10805003.0   \n",
       "4     10.000000000000002             36367.0               136.0  10805003.0   \n",
       "...                  ...                 ...                 ...         ...   \n",
       "1495                11.0            195371.0               281.0  10805003.0   \n",
       "1496                 8.0                 0.0                 0.0  10805003.0   \n",
       "1497  10.000000000000002  31222.000000000004               138.0  10805003.0   \n",
       "1498                11.0             10180.0               125.0  10805003.0   \n",
       "1499                 8.0                 0.0                 0.0  10805003.0   \n",
       "\n",
       "     PINGMAX  \n",
       "0          -  \n",
       "1          -  \n",
       "2       79.0  \n",
       "3          -  \n",
       "4          -  \n",
       "...      ...  \n",
       "1495       -  \n",
       "1496    76.0  \n",
       "1497       -  \n",
       "1498       -  \n",
       "1499       -  \n",
       "\n",
       "[1500 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_csv = getOriginalData(original_data = selected_data, \n",
    "                              categorical_data = original_data['PINGMAX'], \n",
    "                              decoded_data = X_train)\n",
    "original_csv = pd.DataFrame(original_csv, \n",
    "             columns = ['CellID','RSRP','RSRQ','SNR','CQI','DL_bitrate',\n",
    "                        'UL_bitrate','RAWCELLID', 'PINGMAX'])\n",
    "original_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fea04-c14e-4163-ad82-8bdc17a92207",
   "metadata": {},
   "source": [
    "## Encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c49bab-957b-4357-8742-7294402644ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encode0</th>\n",
       "      <th>Encode1</th>\n",
       "      <th>Encode2</th>\n",
       "      <th>Encode3</th>\n",
       "      <th>Encode4</th>\n",
       "      <th>Encode5</th>\n",
       "      <th>Encode6</th>\n",
       "      <th>Encode7</th>\n",
       "      <th>Encode8</th>\n",
       "      <th>Encode9</th>\n",
       "      <th>...</th>\n",
       "      <th>Encode20</th>\n",
       "      <th>Encode21</th>\n",
       "      <th>Encode22</th>\n",
       "      <th>Encode23</th>\n",
       "      <th>Encode24</th>\n",
       "      <th>Encode25</th>\n",
       "      <th>Encode26</th>\n",
       "      <th>Encode27</th>\n",
       "      <th>Encode28</th>\n",
       "      <th>Encode29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.162363</td>\n",
       "      <td>0.039636</td>\n",
       "      <td>0.507975</td>\n",
       "      <td>-0.178750</td>\n",
       "      <td>-0.032879</td>\n",
       "      <td>-0.133882</td>\n",
       "      <td>0.046354</td>\n",
       "      <td>0.309284</td>\n",
       "      <td>-0.293497</td>\n",
       "      <td>0.042558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036838</td>\n",
       "      <td>-0.021133</td>\n",
       "      <td>0.148603</td>\n",
       "      <td>-0.185396</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>-0.157162</td>\n",
       "      <td>0.292086</td>\n",
       "      <td>-0.381707</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.077881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072123</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>0.501548</td>\n",
       "      <td>-0.182824</td>\n",
       "      <td>-0.069275</td>\n",
       "      <td>-0.162785</td>\n",
       "      <td>0.140587</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>-0.303448</td>\n",
       "      <td>0.091091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129996</td>\n",
       "      <td>-0.042667</td>\n",
       "      <td>0.089736</td>\n",
       "      <td>-0.185908</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>-0.195806</td>\n",
       "      <td>0.348472</td>\n",
       "      <td>-0.353341</td>\n",
       "      <td>0.247319</td>\n",
       "      <td>0.036808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023469</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>-0.151924</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.308863</td>\n",
       "      <td>0.215320</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>-0.429604</td>\n",
       "      <td>0.201402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317060</td>\n",
       "      <td>-0.099394</td>\n",
       "      <td>0.211136</td>\n",
       "      <td>-0.192320</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>-0.271462</td>\n",
       "      <td>0.493542</td>\n",
       "      <td>-0.301709</td>\n",
       "      <td>0.341885</td>\n",
       "      <td>-0.086022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.146254</td>\n",
       "      <td>0.081768</td>\n",
       "      <td>0.576707</td>\n",
       "      <td>-0.145632</td>\n",
       "      <td>-0.064093</td>\n",
       "      <td>-0.272514</td>\n",
       "      <td>0.113942</td>\n",
       "      <td>0.460294</td>\n",
       "      <td>-0.415193</td>\n",
       "      <td>0.109222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217644</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>0.241189</td>\n",
       "      <td>-0.147065</td>\n",
       "      <td>0.201180</td>\n",
       "      <td>-0.281149</td>\n",
       "      <td>0.407387</td>\n",
       "      <td>-0.372273</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>-0.050633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156914</td>\n",
       "      <td>0.060496</td>\n",
       "      <td>0.552794</td>\n",
       "      <td>-0.160279</td>\n",
       "      <td>-0.085974</td>\n",
       "      <td>-0.213909</td>\n",
       "      <td>0.091266</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.383474</td>\n",
       "      <td>0.074049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>-0.096347</td>\n",
       "      <td>0.215155</td>\n",
       "      <td>-0.159429</td>\n",
       "      <td>0.182461</td>\n",
       "      <td>-0.257497</td>\n",
       "      <td>0.383801</td>\n",
       "      <td>-0.380959</td>\n",
       "      <td>0.200594</td>\n",
       "      <td>0.008105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.219013</td>\n",
       "      <td>0.086365</td>\n",
       "      <td>0.618287</td>\n",
       "      <td>0.028912</td>\n",
       "      <td>0.182945</td>\n",
       "      <td>-0.291862</td>\n",
       "      <td>-0.088329</td>\n",
       "      <td>0.398250</td>\n",
       "      <td>-0.445843</td>\n",
       "      <td>0.157510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147132</td>\n",
       "      <td>0.081625</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>-0.197034</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>-0.080728</td>\n",
       "      <td>0.168707</td>\n",
       "      <td>-0.332997</td>\n",
       "      <td>0.341209</td>\n",
       "      <td>-0.035457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.028706</td>\n",
       "      <td>-0.043862</td>\n",
       "      <td>0.589992</td>\n",
       "      <td>-0.225591</td>\n",
       "      <td>-0.180676</td>\n",
       "      <td>-0.181540</td>\n",
       "      <td>0.224955</td>\n",
       "      <td>0.446141</td>\n",
       "      <td>-0.386327</td>\n",
       "      <td>0.113284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192943</td>\n",
       "      <td>-0.106596</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>-0.243986</td>\n",
       "      <td>0.157219</td>\n",
       "      <td>-0.277454</td>\n",
       "      <td>0.451187</td>\n",
       "      <td>-0.424380</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>0.077204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.133910</td>\n",
       "      <td>0.550731</td>\n",
       "      <td>-0.131862</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>-0.296104</td>\n",
       "      <td>0.143571</td>\n",
       "      <td>0.506448</td>\n",
       "      <td>-0.391409</td>\n",
       "      <td>0.179904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259107</td>\n",
       "      <td>-0.063211</td>\n",
       "      <td>0.261013</td>\n",
       "      <td>-0.168192</td>\n",
       "      <td>0.159387</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>0.434873</td>\n",
       "      <td>-0.273457</td>\n",
       "      <td>0.334484</td>\n",
       "      <td>-0.094764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.137754</td>\n",
       "      <td>0.201103</td>\n",
       "      <td>0.500106</td>\n",
       "      <td>-0.123178</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>-0.292007</td>\n",
       "      <td>0.097081</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>-0.382467</td>\n",
       "      <td>0.135715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241373</td>\n",
       "      <td>-0.131184</td>\n",
       "      <td>0.339818</td>\n",
       "      <td>-0.102709</td>\n",
       "      <td>0.221321</td>\n",
       "      <td>-0.251729</td>\n",
       "      <td>0.456825</td>\n",
       "      <td>-0.234408</td>\n",
       "      <td>0.242009</td>\n",
       "      <td>-0.126242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.015651</td>\n",
       "      <td>-0.053215</td>\n",
       "      <td>0.674757</td>\n",
       "      <td>-0.262677</td>\n",
       "      <td>-0.195459</td>\n",
       "      <td>-0.219038</td>\n",
       "      <td>0.267470</td>\n",
       "      <td>0.530172</td>\n",
       "      <td>-0.445103</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228792</td>\n",
       "      <td>-0.112062</td>\n",
       "      <td>0.044084</td>\n",
       "      <td>-0.297298</td>\n",
       "      <td>0.173989</td>\n",
       "      <td>-0.305416</td>\n",
       "      <td>0.522122</td>\n",
       "      <td>-0.472662</td>\n",
       "      <td>0.309528</td>\n",
       "      <td>0.089969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Encode0   Encode1   Encode2   Encode3   Encode4   Encode5   Encode6  \\\n",
       "0     0.162363  0.039636  0.507975 -0.178750 -0.032879 -0.133882  0.046354   \n",
       "1     0.072123  0.018391  0.501548 -0.182824 -0.069275 -0.162785  0.140587   \n",
       "2     0.023469  0.088363  0.585284 -0.151924 -0.036347 -0.308863  0.215320   \n",
       "3     0.146254  0.081768  0.576707 -0.145632 -0.064093 -0.272514  0.113942   \n",
       "4     0.156914  0.060496  0.552794 -0.160279 -0.085974 -0.213909  0.091266   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1495  0.219013  0.086365  0.618287  0.028912  0.182945 -0.291862 -0.088329   \n",
       "1496  0.028706 -0.043862  0.589992 -0.225591 -0.180676 -0.181540  0.224955   \n",
       "1497  0.075100  0.133910  0.550731 -0.131862  0.037422 -0.296104  0.143571   \n",
       "1498  0.137754  0.201103  0.500106 -0.123178  0.025296 -0.292007  0.097081   \n",
       "1499  0.015651 -0.053215  0.674757 -0.262677 -0.195459 -0.219038  0.267470   \n",
       "\n",
       "       Encode7   Encode8   Encode9  ...  Encode20  Encode21  Encode22  \\\n",
       "0     0.309284 -0.293497  0.042558  ...  0.036838 -0.021133  0.148603   \n",
       "1     0.352908 -0.303448  0.091091  ...  0.129996 -0.042667  0.089736   \n",
       "2     0.553400 -0.429604  0.201402  ...  0.317060 -0.099394  0.211136   \n",
       "3     0.460294 -0.415193  0.109222  ...  0.217644 -0.086467  0.241189   \n",
       "4     0.414503 -0.383474  0.074049  ...  0.152941 -0.096347  0.215155   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1495  0.398250 -0.445843  0.157510  ...  0.147132  0.081625  0.442986   \n",
       "1496  0.446141 -0.386327  0.113284  ...  0.192943 -0.106596  0.047414   \n",
       "1497  0.506448 -0.391409  0.179904  ...  0.259107 -0.063211  0.261013   \n",
       "1498  0.502705 -0.382467  0.135715  ...  0.241373 -0.131184  0.339818   \n",
       "1499  0.530172 -0.445103  0.145541  ...  0.228792 -0.112062  0.044084   \n",
       "\n",
       "      Encode23  Encode24  Encode25  Encode26  Encode27  Encode28  Encode29  \n",
       "0    -0.185396  0.098135 -0.157162  0.292086 -0.381707  0.209999  0.077881  \n",
       "1    -0.185908  0.113065 -0.195806  0.348472 -0.353341  0.247319  0.036808  \n",
       "2    -0.192320  0.183779 -0.271462  0.493542 -0.301709  0.341885 -0.086022  \n",
       "3    -0.147065  0.201180 -0.281149  0.407387 -0.372273  0.247408 -0.050633  \n",
       "4    -0.159429  0.182461 -0.257497  0.383801 -0.380959  0.200594  0.008105  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1495 -0.197034  0.023039 -0.080728  0.168707 -0.332997  0.341209 -0.035457  \n",
       "1496 -0.243986  0.157219 -0.277454  0.451187 -0.424380  0.252036  0.077204  \n",
       "1497 -0.168192  0.159387 -0.218000  0.434873 -0.273457  0.334484 -0.094764  \n",
       "1498 -0.102709  0.221321 -0.251729  0.456825 -0.234408  0.242009 -0.126242  \n",
       "1499 -0.297298  0.173989 -0.305416  0.522122 -0.472662  0.309528  0.089969  \n",
       "\n",
       "[1500 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(encoded_data, \n",
    "             columns = ['Encode%s'%(number) for number in range(encoded_data.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2001fe-1faa-4bbf-9e03-d7c0f8553d7b",
   "metadata": {},
   "source": [
    "## Decoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b802aa-8b15-4649-8b49-19a13d0553c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.335633</td>\n",
       "      <td>-97.458664</td>\n",
       "      <td>-14.176364</td>\n",
       "      <td>5.316362</td>\n",
       "      <td>11.139453</td>\n",
       "      <td>126593.414062</td>\n",
       "      <td>400.158295</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.329069</td>\n",
       "      <td>-97.280022</td>\n",
       "      <td>-14.391945</td>\n",
       "      <td>4.681108</td>\n",
       "      <td>11.054911</td>\n",
       "      <td>126223.414062</td>\n",
       "      <td>405.284027</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.283361</td>\n",
       "      <td>-96.726936</td>\n",
       "      <td>-14.681438</td>\n",
       "      <td>4.509181</td>\n",
       "      <td>11.497167</td>\n",
       "      <td>117638.007812</td>\n",
       "      <td>373.234955</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.312831</td>\n",
       "      <td>-96.993027</td>\n",
       "      <td>-14.423570</td>\n",
       "      <td>5.218916</td>\n",
       "      <td>11.420067</td>\n",
       "      <td>116078.242188</td>\n",
       "      <td>384.350891</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.328897</td>\n",
       "      <td>-97.115829</td>\n",
       "      <td>-14.330244</td>\n",
       "      <td>5.336322</td>\n",
       "      <td>11.287884</td>\n",
       "      <td>119475.390625</td>\n",
       "      <td>397.227722</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>11.285090</td>\n",
       "      <td>-97.606369</td>\n",
       "      <td>-13.926720</td>\n",
       "      <td>5.830801</td>\n",
       "      <td>11.898513</td>\n",
       "      <td>120003.335938</td>\n",
       "      <td>349.885925</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>11.327806</td>\n",
       "      <td>-97.041641</td>\n",
       "      <td>-14.619123</td>\n",
       "      <td>4.484382</td>\n",
       "      <td>10.950002</td>\n",
       "      <td>122594.578125</td>\n",
       "      <td>404.638153</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>11.282037</td>\n",
       "      <td>-96.860786</td>\n",
       "      <td>-14.512480</td>\n",
       "      <td>4.840896</td>\n",
       "      <td>11.609942</td>\n",
       "      <td>119184.578125</td>\n",
       "      <td>368.502167</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>11.296329</td>\n",
       "      <td>-96.748512</td>\n",
       "      <td>-14.401352</td>\n",
       "      <td>5.321761</td>\n",
       "      <td>11.691708</td>\n",
       "      <td>117609.601562</td>\n",
       "      <td>381.319824</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>11.307057</td>\n",
       "      <td>-96.858307</td>\n",
       "      <td>-14.784497</td>\n",
       "      <td>4.450348</td>\n",
       "      <td>11.035419</td>\n",
       "      <td>119183.015625</td>\n",
       "      <td>383.684235</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CellID       RSRP       RSRQ       SNR        CQI     DL_bitrate  \\\n",
       "0     11.335633 -97.458664 -14.176364  5.316362  11.139453  126593.414062   \n",
       "1     11.329069 -97.280022 -14.391945  4.681108  11.054911  126223.414062   \n",
       "2     11.283361 -96.726936 -14.681438  4.509181  11.497167  117638.007812   \n",
       "3     11.312831 -96.993027 -14.423570  5.218916  11.420067  116078.242188   \n",
       "4     11.328897 -97.115829 -14.330244  5.336322  11.287884  119475.390625   \n",
       "...         ...        ...        ...       ...        ...            ...   \n",
       "1495  11.285090 -97.606369 -13.926720  5.830801  11.898513  120003.335938   \n",
       "1496  11.327806 -97.041641 -14.619123  4.484382  10.950002  122594.578125   \n",
       "1497  11.282037 -96.860786 -14.512480  4.840896  11.609942  119184.578125   \n",
       "1498  11.296329 -96.748512 -14.401352  5.321761  11.691708  117609.601562   \n",
       "1499  11.307057 -96.858307 -14.784497  4.450348  11.035419  119183.015625   \n",
       "\n",
       "      UL_bitrate   RAWCELLID  \n",
       "0     400.158295  10805003.0  \n",
       "1     405.284027  10805003.0  \n",
       "2     373.234955  10805003.0  \n",
       "3     384.350891  10805003.0  \n",
       "4     397.227722  10805003.0  \n",
       "...          ...         ...  \n",
       "1495  349.885925  10805003.0  \n",
       "1496  404.638153  10805003.0  \n",
       "1497  368.502167  10805003.0  \n",
       "1498  381.319824  10805003.0  \n",
       "1499  383.684235  10805003.0  \n",
       "\n",
       "[1500 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_csv = getOriginalNumericalData(original_data = selected_data, \n",
    "                              categorical_data = original_data['PINGMAX'], \n",
    "                              decoded_data = decoded_data)\n",
    "decoded_csv = pd.DataFrame(decoded_csv, \n",
    "             columns = ['CellID','RSRP','RSRQ','SNR','CQI','DL_bitrate',\n",
    "                        'UL_bitrate','RAWCELLID'])\n",
    "decoded_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
