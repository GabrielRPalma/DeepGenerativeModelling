{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846cbd4a-806d-422c-8d02-53e470fad098",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (Encoding/Decoding) using Auto Encoders\n",
    "#### Contractive autoencoders\n",
    "Author: Gabriel Rodrigues Palma\n",
    "\n",
    "Purpose: Encode and decode 5G data. Also, generate new dasets based on the autoencoders methods.\n",
    "\n",
    "Sourcers: Contractive autoencoders code based on the paper: \n",
    "\n",
    "$\\textbf{Contractive Auto-Encoders: Explicit Invariance During Feature Extraction}$ \n",
    "\n",
    "$\\textit{Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, and Yoshua Bengio. Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, pages 833–840, USA, 2011. Omnipress.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efc5f6-4dd1-42db-8cdd-71f3847a9530",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41a0b28-aec9-474b-8fbf-85b407a2ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# visualisation modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keract import get_activations, display_activations\n",
    "\n",
    "# Deep learning modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Additional packages\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Testing GPU from MacOs\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f3b00-64de-4a26-9422-26ec9aaa0730",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "870b01b1-443e-42d7-ba61-475a4e015eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformCategoricalToBinary(data):\n",
    "    '''Function created to transform categorical data to binary arrays'''\n",
    "    reshapedData = np.array(data).reshape(len(data), -1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(reshapedData)    \n",
    "    return(onehot_encoded)\n",
    "\n",
    "def transformBinaryToCategorical(data, query):\n",
    "    '''Function created to transform binary arrays data to categorical'''\n",
    "    reshapedData = np.array(data).reshape(len(data), -1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(reshapedData)   \n",
    "    query = query\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(list(np.unique(reshapedData)))\n",
    "    inverted = label_encoder.inverse_transform(list(np.argmax(query, axis=1))) \n",
    "    return(inverted)\n",
    "\n",
    "def transformScaledToNonscaled(data, query):\n",
    "    '''Function to obtain original data from scaled one'''\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaled_data = scaler.fit_transform(data) \n",
    "    if query.ndim ==1:\n",
    "        query = query.reshape(1, len(query))\n",
    "    else:\n",
    "        query = query.reshape(len(query), -1)\n",
    "    result = scaler.inverse_transform(query)\n",
    "\n",
    "    return(result)\n",
    "\n",
    "def getOriginalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_numerical_data = decoded_data[:, 0:8]\n",
    "    decoded_categorical_data = np.round(decoded_data[:, 8:42])\n",
    "    numerical_data = transformScaledToNonscaled(data = original_data, \n",
    "                                                query = decoded_numerical_data)\n",
    "    categorical_data = transformBinaryToCategorical(data = categorical_data, \n",
    "                                                    query = decoded_categorical_data)    \n",
    "    result = np.hstack((numerical_data, categorical_data.reshape(len(categorical_data), 1)))\n",
    "\n",
    "    return(result)\n",
    "def getOriginalNumericalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_numerical_data = decoded_data   \n",
    "    numerical_data = transformScaledToNonscaled(data = original_data, \n",
    "                                                query = decoded_numerical_data)\n",
    "    result = numerical_data\n",
    "\n",
    "    return(result)\n",
    "def getOriginalCategoricalData(original_data, categorical_data, decoded_data):\n",
    "    '''Function to obtain original data from decoded data'''\n",
    "    decoded_categorical_data = np.round(decoded_data)\n",
    "    categorical_data = transformBinaryToCategorical(data = categorical_data, \n",
    "                                                    query = decoded_categorical_data)  \n",
    "    result = categorical_data\n",
    "\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d8c72-fa55-427b-9b2f-51f98f854f44",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f7dc15-955a-465f-b3b2-22ab3dad29b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>CellID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>RSRQ</th>\n",
       "      <th>SNR</th>\n",
       "      <th>CQI</th>\n",
       "      <th>DL_bitrate</th>\n",
       "      <th>UL_bitrate</th>\n",
       "      <th>RAWCELLID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2.143000e+03</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.00000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.000000</td>\n",
       "      <td>2143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.999067</td>\n",
       "      <td>-13.856276</td>\n",
       "      <td>3.717219</td>\n",
       "      <td>10.65329</td>\n",
       "      <td>50382.109193</td>\n",
       "      <td>141.879608</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.221694e-07</td>\n",
       "      <td>9.162706e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274617</td>\n",
       "      <td>2.239170</td>\n",
       "      <td>3.260739</td>\n",
       "      <td>1.91965</td>\n",
       "      <td>65620.519457</td>\n",
       "      <td>122.211380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3229.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>23853.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.394628e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>61175.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.394624e+00</td>\n",
       "      <td>5.188614e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-93.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>302694.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "      <td>10805003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Longitude      Latitude   Speed  CellID         RSRP         RSRQ  \\\n",
       "count  2.143000e+03  2.143000e+03  2143.0  2143.0  2143.000000  2143.000000   \n",
       "mean  -8.394628e+00  5.188614e+01     0.0    11.0   -95.999067   -13.856276   \n",
       "std    1.221694e-07  9.162706e-08     0.0     0.0     1.274617     2.239170   \n",
       "min   -8.394628e+00  5.188614e+01     0.0    11.0  -104.000000   -19.000000   \n",
       "25%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -16.000000   \n",
       "50%   -8.394628e+00  5.188614e+01     0.0    11.0   -96.000000   -14.000000   \n",
       "75%   -8.394628e+00  5.188614e+01     0.0    11.0   -95.000000   -12.000000   \n",
       "max   -8.394624e+00  5.188614e+01     0.0    11.0   -93.000000    -9.000000   \n",
       "\n",
       "               SNR         CQI     DL_bitrate   UL_bitrate   RAWCELLID  \n",
       "count  2143.000000  2143.00000    2143.000000  2143.000000      2143.0  \n",
       "mean      3.717219    10.65329   50382.109193   141.879608  10805003.0  \n",
       "std       3.260739     1.91965   65620.519457   122.211380         0.0  \n",
       "min      -7.000000     6.00000       0.000000     0.000000  10805003.0  \n",
       "25%       2.000000    10.00000    3229.500000    44.000000  10805003.0  \n",
       "50%       4.000000    11.00000   23853.000000   128.000000  10805003.0  \n",
       "75%       6.000000    11.00000   61175.000000   215.000000  10805003.0  \n",
       "max      15.000000    15.00000  302694.000000  1215.000000  10805003.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv('../../../Data/5G-production-dataset/Download/Static/B_2019.12.16_13.40.04.csv')\n",
    "encoded_text_data = transformCategoricalToBinary(original_data['PINGMAX'])\n",
    "original_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c96ded8-edfa-4294-87ba-6ee460f49081",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_data = transformCategoricalToBinary(original_data['PINGMAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7220f6c9-7750-486e-acfa-4eeeff52e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = original_data[['CellID','RSRP','RSRQ','SNR','CQI','DL_bitrate','UL_bitrate','RAWCELLID']]\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(selected_data)\n",
    "data_scaled = scaler.transform(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9c4c1a-8129-43ba-9708-bd99b757d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((data_scaled, encoded_text_data))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59112bae-d9f4-44d5-8540-0893a2adb75d",
   "metadata": {},
   "source": [
    "# Auto encoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe3b9d5-5e3f-450a-868e-b48ef5695e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 30)                1050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 34)                714       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,384\n",
      "Trainable params: 2,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lam = 0.01\n",
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(30, input_shape=(34, ), activation=\"relu\", activity_regularizer=L1(lam)))\n",
    "autoencoder.add(Dense(20, input_shape=(42, ), activation=\"relu\", activity_regularizer=L1(lam)))\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(34, activation = \"sigmoid\", activity_regularizer=L1(lam)))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c932a5-2d60-42b1-aa4b-77ed2eb32cf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7621 - accuracy: 0.9273\n",
      "Epoch 2/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.9273\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7605 - accuracy: 0.9273\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7597 - accuracy: 0.9273\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7589 - accuracy: 0.9273\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7581 - accuracy: 0.9273\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7573 - accuracy: 0.9273\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7565 - accuracy: 0.9273\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7557 - accuracy: 0.9273\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7549 - accuracy: 0.9273\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7540 - accuracy: 0.9273\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7532 - accuracy: 0.9273\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7523 - accuracy: 0.9273\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7515 - accuracy: 0.9273\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7506 - accuracy: 0.9273\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7498 - accuracy: 0.9273\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7489 - accuracy: 0.9273\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7481 - accuracy: 0.9273\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7472 - accuracy: 0.9267\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7463 - accuracy: 0.9267\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7454 - accuracy: 0.9267\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7445 - accuracy: 0.9267\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7436 - accuracy: 0.9267\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7427 - accuracy: 0.9267\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7418 - accuracy: 0.9267\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7409 - accuracy: 0.9267\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.9267\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.9267\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7381 - accuracy: 0.9267\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7372 - accuracy: 0.9267\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.9267\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7353 - accuracy: 0.9267\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7343 - accuracy: 0.9267\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7333 - accuracy: 0.9267\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.9267\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7314 - accuracy: 0.9267\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7304 - accuracy: 0.9267\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7294 - accuracy: 0.9267\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7284 - accuracy: 0.9267\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.9267\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7264 - accuracy: 0.9267\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7254 - accuracy: 0.9267\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7244 - accuracy: 0.9267\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.9267\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7223 - accuracy: 0.9267\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7213 - accuracy: 0.9267\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7202 - accuracy: 0.9267\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7192 - accuracy: 0.9267\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7181 - accuracy: 0.9267\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7170 - accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7160 - accuracy: 0.9267\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7149 - accuracy: 0.9267\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.9267\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.9267\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.9267\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.9267\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.7082 - accuracy: 0.9267\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7071 - accuracy: 0.9267\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7060 - accuracy: 0.9267\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7048 - accuracy: 0.9267\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7037 - accuracy: 0.9267\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.9267\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7013 - accuracy: 0.9267\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.7002 - accuracy: 0.9267\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.9267\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.9267\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.9267\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.9267\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.9267\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.9267\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.9267\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.9267\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6893 - accuracy: 0.9267\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.9267\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.9267\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.9267\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.9267\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.9267\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6817 - accuracy: 0.9267\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.9267\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.9267\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.9267\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.9267\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.9267\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.9267\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.9267\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.9267\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.9267\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.9267\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6670 - accuracy: 0.9267\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.9267\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.9267\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6629 - accuracy: 0.9267\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6615 - accuracy: 0.9267\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.9267\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6586 - accuracy: 0.9267\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.9267\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.9267\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.9267\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.9267\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6500 - accuracy: 0.9267\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.9267\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.9267\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.9267\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.9267\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.9267\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.9267\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.9267\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.9267\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.9267\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.9267\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.9267\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.9267\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.9267\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.9267\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.9267\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6240 - accuracy: 0.9267\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.9267\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.9267\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.9267\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.9267\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6160 - accuracy: 0.9267\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.9267\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.9267\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6111 - accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.9267\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6061 - accuracy: 0.9267\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.9267\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.9267\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.9267\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.9267\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.9267\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.9267\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.9267\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.9267\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.9267\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.9267\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.9267\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.9267\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.9267\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.9267\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.9267\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.9267\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.9267\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.9267\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.9267\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.9267\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.9267\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.9267\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.9267\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5646 - accuracy: 0.9267\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.9267\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.9267\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5592 - accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.9267\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5556 - accuracy: 0.9267\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.9267\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.9267\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.9267\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.9267\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.9267\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.9267\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.9267\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.9267\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.9267\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.9267\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.9267\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.9267\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.9267\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.9267\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.9267\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.9267\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.9267\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.9267\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.9267\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.9267\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.9267\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.9267\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.9267\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.9267\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.9267\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.9267\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.9267\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.9267\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.9267\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.9267\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.9267\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.9267\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.9267\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294476be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train[:, 8:42], X_train[:, 8:42], epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fed33-e6e3-4135-9c62-a30bea31ea18",
   "metadata": {},
   "source": [
    "## Obtaining numerical encoded and decoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88208b94-296d-49ec-958f-b054c2659678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 880us/step\n",
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 14:24:41.628765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encoded_data = encoder.predict(X_train[:, 8:42])\n",
    "\n",
    "#show_encodings(encodings, number = 1)\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_data = autoencoder.predict(X_train[:, 8:42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81543a2f-1c49-4b61-ab4d-230e8f1017b8",
   "metadata": {},
   "source": [
    "# Showing autoencoder results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5746e3-e1bf-4e47-ba4b-49b151d7bb18",
   "metadata": {},
   "source": [
    "## Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "947e1165-3e49-41ba-a7ef-9b6c4eeb4649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINGMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PINGMAX\n",
       "count     1500\n",
       "unique      28\n",
       "top          -\n",
       "freq      1390"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_csv = getOriginalCategoricalData(original_data = selected_data, \n",
    "                              categorical_data = original_data['PINGMAX'], \n",
    "                              decoded_data = X_train[:, 8:42])\n",
    "original_csv = pd.DataFrame(original_csv, \n",
    "             columns = ['PINGMAX'])\n",
    "original_csv.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb8538-7221-4648-aec3-6244381124b3",
   "metadata": {},
   "source": [
    "## Encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34456675-0ad9-49dc-a46f-055ca02d1b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encode0</th>\n",
       "      <th>Encode1</th>\n",
       "      <th>Encode2</th>\n",
       "      <th>Encode3</th>\n",
       "      <th>Encode4</th>\n",
       "      <th>Encode5</th>\n",
       "      <th>Encode6</th>\n",
       "      <th>Encode7</th>\n",
       "      <th>Encode8</th>\n",
       "      <th>Encode9</th>\n",
       "      <th>...</th>\n",
       "      <th>Encode20</th>\n",
       "      <th>Encode21</th>\n",
       "      <th>Encode22</th>\n",
       "      <th>Encode23</th>\n",
       "      <th>Encode24</th>\n",
       "      <th>Encode25</th>\n",
       "      <th>Encode26</th>\n",
       "      <th>Encode27</th>\n",
       "      <th>Encode28</th>\n",
       "      <th>Encode29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253177</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>0.06223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Encode0   Encode1   Encode2  Encode3   Encode4  Encode5  Encode6  \\\n",
       "0         0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "1         0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "2         0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "3         0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "4         0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "...       ...       ...       ...      ...       ...      ...      ...   \n",
       "2138      0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "2139      0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "2140      0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "2141      0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "2142      0.0  0.253177  0.045052      0.0  0.058791      0.0      0.0   \n",
       "\n",
       "       Encode7   Encode8  Encode9  ...  Encode20  Encode21  Encode22  \\\n",
       "0     0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "1     0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "2     0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "3     0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "4     0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "...        ...       ...      ...  ...       ...       ...       ...   \n",
       "2138  0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "2139  0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "2140  0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "2141  0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "2142  0.323782  0.392704      0.0  ...   0.08134       0.0       0.0   \n",
       "\n",
       "      Encode23  Encode24  Encode25  Encode26  Encode27  Encode28  Encode29  \n",
       "0     0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "1     0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "2     0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "3     0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "4     0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2138  0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "2139  0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "2140  0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "2141  0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "2142  0.279881       0.0       0.0  0.064823   0.06223       0.0    0.1309  \n",
       "\n",
       "[2143 rows x 30 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(encoded_data, \n",
    "             columns = ['Encode%s'%(number) for number in range(encoded_data.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca5276-357f-46bf-a386-7da6944bb86c",
   "metadata": {},
   "source": [
    "## Decoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13b16a9b-90f6-4183-95d9-368df6637db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINGMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PINGMAX\n",
       "count     1500\n",
       "unique       1\n",
       "top          -\n",
       "freq      1500"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_csv = getOriginalCategoricalData(original_data = selected_data, \n",
    "                              categorical_data = original_data['PINGMAX'], \n",
    "                              decoded_data = decoded_data)\n",
    "decoded_csv = pd.DataFrame(decoded_csv, \n",
    "             columns = ['PINGMAX'])\n",
    "decoded_csv.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
